{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## useful notebook features.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2025-06-13T11:16:16.460683Z","iopub.execute_input":"2025-06-13T11:16:16.460987Z","iopub.status.idle":"2025-06-13T11:16:16.466133Z","shell.execute_reply.started":"2025-06-13T11:16:16.460965Z","shell.execute_reply":"2025-06-13T11:16:16.465090Z"}}},{"cell_type":"code","source":"\nfrom pathlib import Path\nimport pickle, gzip, math, os, time, shutil, matplotlib as mpl, matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:16:34.831012Z","iopub.execute_input":"2025-06-13T11:16:34.831346Z","iopub.status.idle":"2025-06-13T11:16:34.836816Z","shell.execute_reply.started":"2025-06-13T11:16:34.831325Z","shell.execute_reply":"2025-06-13T11:16:34.835877Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"a=\"hello\"; a","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:17:41.130235Z","iopub.execute_input":"2025-06-13T11:17:41.130559Z","iopub.status.idle":"2025-06-13T11:17:41.138266Z","shell.execute_reply.started":"2025-06-13T11:17:41.130536Z","shell.execute_reply":"2025-06-13T11:17:41.137363Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'hello'"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"%%time\nnorm=a*a.sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:16:42.428961Z","iopub.execute_input":"2025-06-13T11:16:42.429439Z","iopub.status.idle":"2025-06-13T11:16:42.436194Z","shell.execute_reply.started":"2025-06-13T11:16:42.429406Z","shell.execute_reply":"2025-06-13T11:16:42.434973Z"}},"outputs":[{"name":"stdout","text":"CPU times: user 414 µs, sys: 892 µs, total: 1.31 ms\nWall time: 1.05 ms\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"torch.sum?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:15:35.375357Z","iopub.execute_input":"2025-06-13T11:15:35.375696Z","iopub.status.idle":"2025-06-13T11:15:35.381388Z","shell.execute_reply.started":"2025-06-13T11:15:35.375672Z","shell.execute_reply":"2025-06-13T11:15:35.380324Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mDocstring:\u001b[0m\nsum(input, *, dtype=None) -> Tensor\n\nReturns the sum of all elements in the :attr:`input` tensor.\n\nArgs:\n    input (Tensor): the input tensor.\n\nKeyword args:\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n        If specified, the input tensor is casted to :attr:`dtype` before the operation\n        is performed. This is useful for preventing data type overflows. Default: None.\n\n.. note:: Use the `dtype` argument if you need the result in a specific tensor type.\n          Otherwise, the result type may be automatically promoted (e.g., from `torch.int32` to `torch.int64`).\n\nExample::\n\n    >>> a = torch.randn(1, 3)\n    >>> a\n    tensor([[ 0.1133, -0.9567,  0.2958]])\n    >>> torch.sum(a)\n    tensor(-0.5475)\n\n.. function:: sum(input, dim, keepdim=False, *, dtype=None) -> Tensor\n   :noindex:\n\nReturns the sum of each row of the :attr:`input` tensor in the given\ndimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\nreduce over all of them.\n\n\nIf :attr:`keepdim` is ``True``, the output tensor is of the same size\nas :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\nOtherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\noutput tensor having 1 (or ``len(dim)``) fewer dimension(s).\n\n\nArgs:\n    input (Tensor): the input tensor.\n    \n    dim (int or tuple of ints, optional): the dimension or dimensions to reduce.\n        If ``None``, all dimensions are reduced.\n\n    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n\nKeyword args:\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n        If specified, the input tensor is casted to :attr:`dtype` before the operation\n        is performed. This is useful for preventing data type overflows. Default: None.\n\nExample::\n\n    >>> a = torch.randn(4, 4)\n    >>> a\n    tensor([[ 0.0569, -0.2475,  0.0737, -0.3429],\n            [-0.2993,  0.9138,  0.9337, -1.6864],\n            [ 0.1132,  0.7892, -0.1003,  0.5688],\n            [ 0.3637, -0.9906, -0.4752, -1.5197]])\n    >>> torch.sum(a, 1)\n    tensor([-0.4598, -0.1381,  1.3708, -2.6217])\n    >>> b = torch.arange(4 * 5 * 6).view(4, 5, 6)\n    >>> torch.sum(b, (2, 1))\n    tensor([  435.,  1335.,  2235.,  3135.])\n\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"def a():\n    return \"something\";","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:18:27.550315Z","iopub.execute_input":"2025-06-13T11:18:27.550711Z","iopub.status.idle":"2025-06-13T11:18:27.555128Z","shell.execute_reply.started":"2025-06-13T11:18:27.550689Z","shell.execute_reply":"2025-06-13T11:18:27.554133Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"%%","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:18:51.771846Z","iopub.execute_input":"2025-06-13T11:18:51.772211Z","iopub.status.idle":"2025-06-13T11:18:51.778476Z","shell.execute_reply.started":"2025-06-13T11:18:51.772185Z","shell.execute_reply":"2025-06-13T11:18:51.776829Z"}},"outputs":[{"name":"stderr","text":"UsageError: Cell magic `%%run` not found (But line magic `%run` exists, did you mean that instead?).\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"!pip install numpy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:19:48.602554Z","iopub.execute_input":"2025-06-13T11:19:48.602853Z","iopub.status.idle":"2025-06-13T11:19:54.021608Z","shell.execute_reply.started":"2025-06-13T11:19:48.602834Z","shell.execute_reply":"2025-06-13T11:19:54.020324Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"a?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:26:52.023949Z","iopub.execute_input":"2025-06-13T11:26:52.024365Z","iopub.status.idle":"2025-06-13T11:26:52.079509Z","shell.execute_reply.started":"2025-06-13T11:26:52.024330Z","shell.execute_reply":"2025-06-13T11:26:52.078132Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mSignature:\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m <no docstring>\n\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_35/553795957.py\n\u001b[0;31mType:\u001b[0m      function\n"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"import keras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:27:21.783438Z","iopub.execute_input":"2025-06-13T11:27:21.783856Z","iopub.status.idle":"2025-06-13T11:27:41.966724Z","shell.execute_reply.started":"2025-06-13T11:27:21.783827Z","shell.execute_reply":"2025-06-13T11:27:41.965640Z"}},"outputs":[{"name":"stderr","text":"2025-06-13 11:27:24.580773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749814044.944959      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749814045.034006      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from keras import Sequential","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:27:41.968171Z","iopub.execute_input":"2025-06-13T11:27:41.968831Z","iopub.status.idle":"2025-06-13T11:27:41.973725Z","shell.execute_reply.started":"2025-06-13T11:27:41.968805Z","shell.execute_reply":"2025-06-13T11:27:41.972668Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"Sequential?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:27:41.974637Z","iopub.execute_input":"2025-06-13T11:27:41.974893Z","iopub.status.idle":"2025-06-13T11:27:42.010347Z","shell.execute_reply.started":"2025-06-13T11:27:41.974873Z","shell.execute_reply":"2025-06-13T11:27:42.009312Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mInit signature:\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \n`Sequential` groups a linear stack of layers into a `Model`.\n\nExamples:\n\n```python\nmodel = keras.Sequential()\nmodel.add(keras.Input(shape=(16,)))\nmodel.add(keras.layers.Dense(8))\n\n# Note that you can also omit the initial `Input`.\n# In that case the model doesn't have any weights until the first call\n# to a training/evaluation method (since it isn't yet built):\nmodel = keras.Sequential()\nmodel.add(keras.layers.Dense(8))\nmodel.add(keras.layers.Dense(4))\n# model.weights not created yet\n\n# Whereas if you specify an `Input`, the model gets built\n# continuously as you are adding layers:\nmodel = keras.Sequential()\nmodel.add(keras.Input(shape=(16,)))\nmodel.add(keras.layers.Dense(8))\nlen(model.weights)  # Returns \"2\"\n\n# When using the delayed-build pattern (no input shape specified), you can\n# choose to manually build your model by calling\n# `build(batch_input_shape)`:\nmodel = keras.Sequential()\nmodel.add(keras.layers.Dense(8))\nmodel.add(keras.layers.Dense(4))\nmodel.build((None, 16))\nlen(model.weights)  # Returns \"4\"\n\n# Note that when using the delayed-build pattern (no input shape specified),\n# the model gets built the first time you call `fit`, `eval`, or `predict`,\n# or the first time you call the model on some input data.\nmodel = keras.Sequential()\nmodel.add(keras.layers.Dense(8))\nmodel.add(keras.layers.Dense(1))\nmodel.compile(optimizer='sgd', loss='mse')\n# This builds the model for the first time:\nmodel.fit(x, y, batch_size=32, epochs=10)\n```\n\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.11/dist-packages/keras/src/models/sequential.py\n\u001b[0;31mType:\u001b[0m           type\n\u001b[0;31mSubclasses:\u001b[0m     \n"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"%colors Linux\n# print(\"hello\")?\n%timeit?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T11:29:18.612703Z","iopub.execute_input":"2025-06-13T11:29:18.613006Z","iopub.status.idle":"2025-06-13T11:29:18.619097Z","shell.execute_reply.started":"2025-06-13T11:29:18.612985Z","shell.execute_reply":"2025-06-13T11:29:18.617649Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1;31mDocstring:\u001b[0m\nTime execution of a Python statement or expression\n\nUsage, in line mode:\n  %timeit [-n<N> -r<R> [-t|-c] -q -p<P> -o] statement\nor in cell mode:\n  %%timeit [-n<N> -r<R> [-t|-c] -q -p<P> -o] setup_code\n  code\n  code...\n\nTime execution of a Python statement or expression using the timeit\nmodule.  This function can be used both as a line and cell magic:\n\n- In line mode you can time a single-line statement (though multiple\n  ones can be chained with using semicolons).\n\n- In cell mode, the statement in the first line is used as setup code\n  (executed but not timed) and the body of the cell is timed.  The cell\n  body has access to any variables created in the setup code.\n\nOptions:\n-n<N>: execute the given statement <N> times in a loop. If <N> is not\nprovided, <N> is determined so as to get sufficient accuracy.\n\n-r<R>: number of repeats <R>, each consisting of <N> loops, and take the\nbest result.\nDefault: 7\n\n-t: use time.time to measure the time, which is the default on Unix.\nThis function measures wall time.\n\n-c: use time.clock to measure the time, which is the default on\nWindows and measures wall time. On Unix, resource.getrusage is used\ninstead and returns the CPU user time.\n\n-p<P>: use a precision of <P> digits to display the timing result.\nDefault: 3\n\n-q: Quiet, do not print result.\n\n-o: return a TimeitResult that can be stored in a variable to inspect\n    the result in more details.\n\n.. versionchanged:: 7.3\n    User variables are no longer expanded,\n    the magic line is always left unmodified.\n\nExamples\n--------\n::\n\n  In [1]: %timeit pass\n  8.26 ns ± 0.12 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n\n  In [2]: u = None\n\n  In [3]: %timeit u is None\n  29.9 ns ± 0.643 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each)\n\n  In [4]: %timeit -r 4 u == None\n\n  In [5]: import time\n\n  In [6]: %timeit -n1 time.sleep(2)\n\n\nThe times reported by %timeit will be slightly higher than those\nreported by the timeit.py script when variables are accessed. This is\ndue to the fact that %timeit executes the statement in the namespace\nof the shell, compared with timeit.py, which uses a single setup\nstatement to import function or create variables. Generally, the bias\ndoes not matter as long as results from timeit.py are not mixed with\nthose from %timeit.\n\u001b[1;31mFile:\u001b[0m      /usr/local/lib/python3.11/dist-packages/IPython/core/magics/execution.py\n"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}